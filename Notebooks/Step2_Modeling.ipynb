{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "The focus of this notebook is to continue the NLP steps with the text data that has now been turned into a feather file (file name and its corresponding text). Within this notebook you will see the making of the baseline model and model improvements.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Importing and Manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import mean\n",
    "\n",
    "#Sentiment Analysis\n",
    "from textblob import TextBlob\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "\n",
    "# Tokenizing\n",
    "from textblob.taggers import NLTKTagger\n",
    "\n",
    "# Time series handling \n",
    "import datetime\n",
    "\n",
    "\n",
    "# # Cleaning up memory on computer after running code\n",
    "# import gc; gc.enable()\n",
    "\n",
    "# import string\n",
    "\n",
    "# # String handling and NLP model\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# import nltk\n",
    "# from nltk import word_tokenize\n",
    "# from nltk.tokenize import treebank\n",
    "# # nltk.download('opinion_lexicon')\n",
    "# # nltk.download('vader_lexicon')\n",
    "# # nltk.download('punkt')\n",
    "# from nltk.corpus import opinion_lexicon\n",
    "\n",
    "# from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0000092122-17-000024.txt</td>\n",
       "      <td>txt hdrsgml access number conform submiss type...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0000092122-18-000050.txt</td>\n",
       "      <td>txt hdrsgml access number conform submiss type...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0000092122-19-000016.txt</td>\n",
       "      <td>txt hdrsgml access number conform submiss type...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0000092122-18-000027.txt</td>\n",
       "      <td>txt hdrsgml access number conform submiss type...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0000092122-16-000213.txt</td>\n",
       "      <td>txt hdrsgml access number conform submiss type...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  file_name                                               text\n",
       "0  0000092122-17-000024.txt  txt hdrsgml access number conform submiss type...\n",
       "1  0000092122-18-000050.txt  txt hdrsgml access number conform submiss type...\n",
       "2  0000092122-19-000016.txt  txt hdrsgml access number conform submiss type...\n",
       "3  0000092122-18-000027.txt  txt hdrsgml access number conform submiss type...\n",
       "4  0000092122-16-000213.txt  txt hdrsgml access number conform submiss type..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading from 'Feather' format\n",
    "df = pd.read_feather('/Users/boimoriba/Documents/Learn.Co_Docs/Projects/Capstone/QQuarterlyInc/CSV_Files/10-Qs.feather')\n",
    "del df['index']; gc.collect()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape # Viewing the shape of the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'16'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Year'] = [2017, 2018, 2019, 2018, 2016, 2020, 2017, 2016, 2016, 2019, 2017, 2019, 2018] \n",
    "# df['file_name'][7][11:13]\n",
    "# How you find the year document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "While condicting online research I came across a YouTube video that went through using the library Textblob. In the previous notbook we were able to remove punctuations, stopwords, and digets(could not parse through because of te timeframe we have. \n",
    "\n",
    "This can be done in the near future). We were also able to nomalize the text and create a dataframe from the nomalized text and its corresponding file name. Below you will see my attemped to perform a sentiment analysis on the text data in the df we currently have. The documentation for this library is located in the resource section. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Run\n",
    "**Lets try using the libray on one body of text from the df.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Textblob obj to be used for analysis\n",
    "obj = TextBlob(df.text[10]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returning a value between 1 & -1\n",
    "# Using initiated obj to get polarity value\n",
    "sentiment = obj.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.014091192227164666, subjectivity=0.23202066756152523)\n"
     ]
    }
   ],
   "source": [
    "print(sentiment) # Printing results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turn It Into A Function\n",
    "It worked! Now lets try this for every text body in the df by writing a function!! The below cells will consist of two function; one providing the list of sentiment polarity values for each body of text in df[*text*] & another displaying if the text is negative, positive or neutral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This function will take in the df as an argument and \n",
    "iterate through the text column that is sliced to the body \n",
    "of text its self and return a list of sentiment polarity value \n",
    "for each body of text'''\n",
    "def sentiment_ana(df):\n",
    "    sentiments_list = []\n",
    "    i = [0,1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "    for text in df.text[i]:\n",
    "            obj = TextBlob(text)\n",
    "            sentiment = obj.sentiment.polarity\n",
    "            sentiments_list.append(sentiment)\n",
    "    return sentiments_list \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "SO_Sentiments = sentiment_ana(df) # Calling function and assigning to variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.025743580469827186,\n",
       " -0.0033127985425172066,\n",
       " 0.03165365439445174,\n",
       " 0.02479712515096895,\n",
       " 0.019257323182357684,\n",
       " 0.018702514236993255,\n",
       " 0.014686811941619592,\n",
       " 0.030788767127009578,\n",
       " 0.024793322909917113,\n",
       " 0.047629955462548425,\n",
       " 0.014091192227164666,\n",
       " 0.024803428417207694,\n",
       " 0.01055402079920463]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SO_Sentiments # Viewing list of polarity values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qucik Observation\n",
    "Now that we have a list of floats that represent each body of text in the df (all 13 10-Qs for Southern Co), lets find the avereage the get and idea of what the over all sentiment of the documents are. You will see the overall language of the documents are positive. But we need a model to predict the next documents sentiment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02186068444436564\n",
      "The Text Is Positive\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SA_Mean = mean(SO_Sentiments)\n",
    "if SA_Mean == 0: \n",
    "    print(SA_Mean)\n",
    "    print('The text Is Neutral')\n",
    "    print('\\n') \n",
    "elif SA_Mean > 0:\n",
    "    print(SA_Mean)\n",
    "    print('The Text Is Positive')\n",
    "    print('\\n') \n",
    "else:\n",
    "    print(SA_Mean)\n",
    "    print('The Text Is Negative')\n",
    "    print('\\n') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is It Positive, Neutral or Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This function will take in the list of polarity values as an argument and \n",
    "iterate through the list, check if the value meets any of the conditions,\n",
    "and print the text that matches the values met condition.'''\n",
    "def SA(_list):\n",
    "    for sentiment in _list:\n",
    "        if sentiment == 0: \n",
    "            print(sentiment)\n",
    "            print('The text Is Neutral')\n",
    "            print('\\n') \n",
    "        elif sentiment > 0:\n",
    "            print(sentiment)\n",
    "            print('The Text Is Positive')\n",
    "            print('\\n') \n",
    "        else:\n",
    "            print(sentiment)\n",
    "            print('The Text Is Negative')\n",
    "            print('\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.025743580469827186\n",
      "The Text Is Positive\n",
      "\n",
      "\n",
      "-0.0033127985425172066\n",
      "The Text Is Negative\n",
      "\n",
      "\n",
      "0.03165365439445174\n",
      "The Text Is Positive\n",
      "\n",
      "\n",
      "0.02479712515096895\n",
      "The Text Is Positive\n",
      "\n",
      "\n",
      "0.019257323182357684\n",
      "The Text Is Positive\n",
      "\n",
      "\n",
      "0.018702514236993255\n",
      "The Text Is Positive\n",
      "\n",
      "\n",
      "0.014686811941619592\n",
      "The Text Is Positive\n",
      "\n",
      "\n",
      "0.030788767127009578\n",
      "The Text Is Positive\n",
      "\n",
      "\n",
      "0.024793322909917113\n",
      "The Text Is Positive\n",
      "\n",
      "\n",
      "0.047629955462548425\n",
      "The Text Is Positive\n",
      "\n",
      "\n",
      "0.014091192227164666\n",
      "The Text Is Positive\n",
      "\n",
      "\n",
      "0.024803428417207694\n",
      "The Text Is Positive\n",
      "\n",
      "\n",
      "0.01055402079920463\n",
      "The Text Is Positive\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Sentiment_Results = SA(SO_Sentiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Run 2\n",
    "Looking into the advance use of Textblob I was able to find code that can do the sentiment analysis of the text for me, in just a few lines of code. This code was taken from the Textblod documentation. The link to this code is provided in the Resource Section of the notebook. Lets test out this code  ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(classification='pos', p_pos=1.0, p_neg=7.994055237498093e-59)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLTK classifier trained on a movie reviews corpus.\n",
    "# Using trained NB Analyzer to do sentiment analysis on a body of text\n",
    "blob = TextBlob(df.text[0], analyzer=NaiveBayesAnalyzer())\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentiment(polarity=0.025743580469827186, subjectivity=0.2540728170602351),\n",
       " Sentiment(polarity=-0.0033127985425172066, subjectivity=0.21546182328981334),\n",
       " Sentiment(polarity=0.03165365439445174, subjectivity=0.2412985417005685),\n",
       " Sentiment(polarity=0.02479712515096895, subjectivity=0.24103082251213098),\n",
       " Sentiment(polarity=0.019257323182357684, subjectivity=0.24951626760818546),\n",
       " Sentiment(polarity=0.018702514236993255, subjectivity=0.3198025500406785),\n",
       " Sentiment(polarity=0.014686811941619592, subjectivity=0.2394814773079978),\n",
       " Sentiment(polarity=0.030788767127009578, subjectivity=0.2808617455424036),\n",
       " Sentiment(polarity=0.024793322909917113, subjectivity=0.26371509564186707),\n",
       " Sentiment(polarity=0.047629955462548425, subjectivity=0.29089749264666365),\n",
       " Sentiment(polarity=0.014091192227164666, subjectivity=0.23202066756152523),\n",
       " Sentiment(polarity=0.024803428417207694, subjectivity=0.22793639634486648),\n",
       " Sentiment(polarity=0.01055402079920463, subjectivity=0.24379420524338227)]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SA_p2 = sentiment_ana2(df)\n",
    "SA_p2\n",
    "# polarity is how positive or neg text is between -1 & 1\n",
    "# subjectivity is how opinionated the text seems to be, between -1 & 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_ana3(df):\n",
    "    sentiments_list = []\n",
    "    i = [0,1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "    for text in df.text[i]:\n",
    "            blob = TextBlob(text, analyzer=NaiveBayesAnalyzer())\n",
    "            sentiments = blob.sentiment\n",
    "            sentiments_list.append(sentiments)\n",
    "    return sentiments_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "SA_p3 = sentiment_ana3(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentiment(classification='pos', p_pos=1.0, p_neg=7.994055237498093e-59),\n",
       " Sentiment(classification='pos', p_pos=1.0, p_neg=1.9328015799642474e-54),\n",
       " Sentiment(classification='pos', p_pos=1.0, p_neg=8.681604915330248e-51),\n",
       " Sentiment(classification='pos', p_pos=1.0, p_neg=8.332839280044437e-45),\n",
       " Sentiment(classification='pos', p_pos=1.0, p_neg=7.02691649602693e-62),\n",
       " Sentiment(classification='pos', p_pos=1.0, p_neg=9.397962013413978e-46),\n",
       " Sentiment(classification='pos', p_pos=1.0, p_neg=4.991106707551972e-91),\n",
       " Sentiment(classification='pos', p_pos=1.0, p_neg=1.9355736723606737e-73),\n",
       " Sentiment(classification='pos', p_pos=1.0, p_neg=2.035307026919699e-60),\n",
       " Sentiment(classification='pos', p_pos=1.0, p_neg=2.438798193514326e-54),\n",
       " Sentiment(classification='pos', p_pos=1.0, p_neg=4.995200663023715e-50),\n",
       " Sentiment(classification='pos', p_pos=1.0, p_neg=2.68729553663566e-53),\n",
       " Sentiment(classification='pos', p_pos=1.0, p_neg=3.896515836791994e-65)]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SA_p3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating list of years the file are from using file_name column\n",
    "df['Year'] = [2017, 2018, 2019, 2018, 2016, 2020, 2017, 2016, 2016, 2019, 2017, 2019, 2018] \n",
    "# df['file_name'][7][11:13]\n",
    "# How you find the year document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>text</th>\n",
       "      <th>Year</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0000092122-17-000024.txt</td>\n",
       "      <td>txt hdrsgml access number conform submiss type...</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.025744</td>\n",
       "      <td>0.254073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0000092122-18-000050.txt</td>\n",
       "      <td>txt hdrsgml access number conform submiss type...</td>\n",
       "      <td>2018</td>\n",
       "      <td>-0.003313</td>\n",
       "      <td>0.215462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0000092122-19-000016.txt</td>\n",
       "      <td>txt hdrsgml access number conform submiss type...</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.031654</td>\n",
       "      <td>0.241299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0000092122-18-000027.txt</td>\n",
       "      <td>txt hdrsgml access number conform submiss type...</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.024797</td>\n",
       "      <td>0.241031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0000092122-16-000213.txt</td>\n",
       "      <td>txt hdrsgml access number conform submiss type...</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.019257</td>\n",
       "      <td>0.249516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0000092122-20-000042.txt</td>\n",
       "      <td>txt hdrsgml access number conform submiss type...</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.018703</td>\n",
       "      <td>0.319803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0000092122-17-000065.txt</td>\n",
       "      <td>txt hdrsgml access number conform submiss type...</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.014687</td>\n",
       "      <td>0.239481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0000092122-16-000144.txt</td>\n",
       "      <td>txt hdrsgml access number conform submiss type...</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.030789</td>\n",
       "      <td>0.280862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0000092122-16-000179.txt</td>\n",
       "      <td>txt hdrsgml access number conform submiss type...</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.024793</td>\n",
       "      <td>0.263715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0000092122-19-000053.txt</td>\n",
       "      <td>txt hdrsgml access number conform submiss type...</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.047630</td>\n",
       "      <td>0.290897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0000092122-17-000076.txt</td>\n",
       "      <td>txt hdrsgml access number conform submiss type...</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.014091</td>\n",
       "      <td>0.232021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0000092122-19-000037.txt</td>\n",
       "      <td>txt hdrsgml access number conform submiss type...</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.024803</td>\n",
       "      <td>0.227936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0000092122-18-000062.txt</td>\n",
       "      <td>txt hdrsgml access number conform submiss type...</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.010554</td>\n",
       "      <td>0.243794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   file_name  \\\n",
       "0   0000092122-17-000024.txt   \n",
       "1   0000092122-18-000050.txt   \n",
       "2   0000092122-19-000016.txt   \n",
       "3   0000092122-18-000027.txt   \n",
       "4   0000092122-16-000213.txt   \n",
       "5   0000092122-20-000042.txt   \n",
       "6   0000092122-17-000065.txt   \n",
       "7   0000092122-16-000144.txt   \n",
       "8   0000092122-16-000179.txt   \n",
       "9   0000092122-19-000053.txt   \n",
       "10  0000092122-17-000076.txt   \n",
       "11  0000092122-19-000037.txt   \n",
       "12  0000092122-18-000062.txt   \n",
       "\n",
       "                                                 text  Year  polarity  \\\n",
       "0   txt hdrsgml access number conform submiss type...  2017  0.025744   \n",
       "1   txt hdrsgml access number conform submiss type...  2018 -0.003313   \n",
       "2   txt hdrsgml access number conform submiss type...  2019  0.031654   \n",
       "3   txt hdrsgml access number conform submiss type...  2018  0.024797   \n",
       "4   txt hdrsgml access number conform submiss type...  2016  0.019257   \n",
       "5   txt hdrsgml access number conform submiss type...  2020  0.018703   \n",
       "6   txt hdrsgml access number conform submiss type...  2017  0.014687   \n",
       "7   txt hdrsgml access number conform submiss type...  2016  0.030789   \n",
       "8   txt hdrsgml access number conform submiss type...  2016  0.024793   \n",
       "9   txt hdrsgml access number conform submiss type...  2019  0.047630   \n",
       "10  txt hdrsgml access number conform submiss type...  2017  0.014091   \n",
       "11  txt hdrsgml access number conform submiss type...  2019  0.024803   \n",
       "12  txt hdrsgml access number conform submiss type...  2018  0.010554   \n",
       "\n",
       "    subjectivity  \n",
       "0       0.254073  \n",
       "1       0.215462  \n",
       "2       0.241299  \n",
       "3       0.241031  \n",
       "4       0.249516  \n",
       "5       0.319803  \n",
       "6       0.239481  \n",
       "7       0.280862  \n",
       "8       0.263715  \n",
       "9       0.290897  \n",
       "10      0.232021  \n",
       "11      0.227936  \n",
       "12      0.243794  "
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code used below cam from Alice Zhao Link to github will be in Resource Section\n",
    "# Code used to calculate the sentiment polar and subjective vale\n",
    "pol = lambda x: TextBlob(x).sentiment.polarity\n",
    "sub = lambda x: TextBlob(x).sentiment.subjectivity\n",
    "\n",
    "df['polarity'] = df['text'].apply(pol)\n",
    "df['subjectivity'] = df['text'].apply(sub)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources\n",
    "\n",
    "**Everything Textblob**\n",
    "\n",
    "Install: https://textblob.readthedocs.io/en/dev/install.html\n",
    "\n",
    "Tutorial: https://textblob.readthedocs.io/en/dev/classifiers.html#classifiers\n",
    "\n",
    "Advance: https://textblob.readthedocs.io/en/dev/advanced_usage.html\n",
    "\n",
    "**Everything YouTube**\n",
    "\n",
    "Sentiment Analysis w/ Textblob: https://www.youtube.com/watch?v=N9CT6Ggh0oE\n",
    "\n",
    "Sentiment Analysis w/ Textblob: https://www.youtube.com/watch?v=bUgKhp8YwO0\n",
    "\n",
    "**Github**\n",
    "Alice Zhao Github Notebook: https://github.com/adashofdata/nlp-in-python-tutorial/blob/master/3-Sentiment-Analysis.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
