{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Upload\n",
    "The purpose of this notebook is to use the python library edgar to request 10-Qs from the SEC.gov website on registered companies. I want to focus on the quaterly reports of companies listed as NYSE stocks; there are 2,800 companies in that list. Once I have the files I will then clean the documents up the prepare them for the modeling phase. The plan is to use 18 companies.\n",
    "\n",
    "**About the data:** The data was obtained from a list of companies that were registered with the SEC. In a scrap notebook I created a dataframe out of that list and cleaned it up. I dropped three columns which lead to the loss of 30,000 companies. This which was fine since the list contained 759,377 companies. \n",
    "\n",
    "Once I had the cleaned dataframe, I then searched for NYSE Companies within the data and created a new dataset. That smaller dataset is what you see being uploaded to this notebook. A link for the original list of SEC Registered companies will be provided in the resource section below. \n",
    "\n",
    "## Objectives:\n",
    "\n",
    "- Download needed documentation from SEC using edgar \n",
    "- Filter documentation to only contain NYSE company files \n",
    "- Turn docments into data frames for easier cleanign process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bringing In the Data With Small Adjustments\n",
    "In the section you will see the data frame created for 18 NYSE Companies of my choice, with their corresponding CIK number. You will then see the creation of an additional column that will have the companies corresponding ticker symbol.Â "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data Importing and Manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Web Scrapping\n",
    "from sec_edgar_downloader import Downloader\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# String Manipulation\n",
    "import re\n",
    "import unicodedata\n",
    "from inscriptis import get_text\n",
    "from cleantext import clean\n",
    "\n",
    "# Cleaning up memory on computer after running code\n",
    "import gc; gc.enable()\n",
    "\n",
    "# Interact with the file systems\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importing the data\n",
    "df = pd.read_csv('/Users/boimoriba/Documents/Learn.Co_Docs/Projects/Capstone/QQuarterlyInc/CSV_Files/SEC Registered NYSE US Companies Down Sampled', index_col='Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'CIK_Num'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns # Checking the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.drop(columns='Unnamed: 0', inplace=True) # Getting rid of extra column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating a new with the companies ticker symbol\n",
    "df['Ticker'] = ['MMM', 'ABT', 'ACN', 'ALGT',\n",
    "                'BKR', 'BAX', 'BA', 'DVN',\n",
    "                'GS', 'GS', 'JNJ', 'MA',\n",
    "                'MS', 'PM', 'PRU', 'RTX',\n",
    "                'SPG', 'SKYW', 'SO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Names:\n",
      "Index(['CIK_Num', 'Ticker'], dtype='object')\n",
      "\n",
      "\n",
      "Data Quick View:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIK_Num</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3M Co</td>\n",
       "      <td>66740</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Abbott Laboratories</td>\n",
       "      <td>1800</td>\n",
       "      <td>ABT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Accenture Plc</td>\n",
       "      <td>1467373</td>\n",
       "      <td>ACN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Allegiant Travel Co</td>\n",
       "      <td>1362468</td>\n",
       "      <td>ALGT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Baker Hughes Co</td>\n",
       "      <td>1701605</td>\n",
       "      <td>BKR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     CIK_Num Ticker\n",
       "Name                               \n",
       "3M Co                  66740    MMM\n",
       "Abbott Laboratories     1800    ABT\n",
       "Accenture Plc        1467373    ACN\n",
       "Allegiant Travel Co  1362468   ALGT\n",
       "Baker Hughes Co      1701605    BKR"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking work\n",
    "print('Column Names:')\n",
    "print(df.columns)\n",
    "print('\\n')\n",
    "print('Data Quick View:')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Company Document Downloads\n",
    "This section will contain the downloading of the documents that will be used for sentiment analysis. The document of focus is the 10-Q or quaterly reports of each company in the dataset between the years of 2016 - 2020. This section of code was obtained from Bryan Arnold. The documentation for the code used will be located in the resource section of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize a downloader instance.\n",
    "# If no argument is passed to the constructor, the package\n",
    "# will attempt to locate the user's downloads folder.\n",
    "# I gave it the absolute path to my project folder\n",
    "\n",
    "dl = Downloader(\"/Users/boimoriba/Documents/Learn.Co_Docs/Projects/Capstone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3M Co: MMM**\n",
    "\n",
    "This is the first attempt at the obtaining the data needed from the downloaded documents. Below you will see this conducted on one of the 10-Qs for 3M Co that was downloaded. If this proves to be sucuessful, then an automated way will be the next step to obtain the remaning text from each downloaded document.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " # Get all 10-Q filings (ticker: MMM )\n",
    "# dl.get(\"10-Q\", \"MMM\", after_date=\"20160101\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reading in the document\n",
    "PATH = \"/Users/boimoriba/Documents/Learn.Co_Docs/Projects/Capstone/QQuarterlyInc/sec_edgar_filings/MMM/10-Q/0001558370-16-005213.txt\"\n",
    "file = open(PATH, \"r\", -1 , \"utf-8\")\n",
    "text = file.read()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(text, 'lxml') # Parsing document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Viewing header of document \n",
    "# sec_header_tag = soup.find('sec-header')\n",
    "# display(sec_header_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLEANING OF THE MMM IMPORTED DOCUMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remove all script and style elements\n",
    "for script in soup([\"script\", \"style\"]):\n",
    "    script.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Assign what's left to a string\n",
    "pageText = soup.body.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pageText = unicodedata.normalize(\"NFKD\", pageText) # Normalizing text format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Getting rid of characters in document\n",
    "pageText = \"\".join(c for c in pageText if c not in '!\"#$%&\\'()*+,./:;<=>?@[\\\\]^_`{|}~') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RISK FACTOR SECTION OF DOCUMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Trying to print the text of the Risk Factor section\n",
    "start = 'ITEM 1A'\n",
    "end = 'ITEM 2'\n",
    "result = re.search('%s(.*)%s' % (start, end), pageText)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Observation \n",
    "As you can see from the cell above, there are non sections in the text labeled \"Item 1A\" or \"Item 2\". My assumption is that each company files their documents in a different style or order. So trying to pull out a certain section will be a long winded task; something I will have to try when there isn't a deadline to meet. \n",
    "\n",
    "## Next Steps\n",
    "Below you will see the code for downloading each companies 10-Qs between 2016-2020. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Languge Processing Steps\n",
    "Since we are working with multiple documents for each company, we will be using TF-IDF. The first thing we will do is create a document paths for each company. The next thing we will need to do turn each company text files into a dataframe; the df will make it easy to clean up the documents; removing stops words & punctuations, turning all uppercase letters to lower case.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3M Co: MMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating the path to list of 10-Qs\n",
    "MMM_Path = \"/Users/boimoriba/Documents/Learn.Co_Docs/Projects/Capstone/QQuarterlyInc/sec_edgar_filings/MMM/10-Q/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abbott Laboratories: ABT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get all 10-Q filings (ticker: ABT )\n",
    "# dl.get(\"10-Q\", \"ABT\", after_date=\"20160101\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating the path to list of 10-Qs\n",
    "ABT_Path = \"/Users/boimoriba/Documents/Learn.Co_Docs/Projects/Capstone/QQuarterlyInc/sec_edgar_filings/ABT/10-Q/\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accenture Plc: ACN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get all 10-Q filings (ticker: ACN )\n",
    "# dl.get(\"10-Q\", \"ACN\", after_date=\"20160101\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating the path to list of 10-Qs\n",
    "ACN_PATH = \"/Users/boimoriba/Documents/Learn.Co_Docs/Projects/Capstone/QQuarterlyInc/sec_edgar_filings/ACN/10-Q/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Allegiant Travel Co: ALGT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get all 10-Q filings (ticker: ALGT )\n",
    "# dl.get(\"10-Q\", \"ALGT\", after_date=\"20160101\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating the path to list of 10-Qs\n",
    "ALGT_Path = \"/Users/boimoriba/Documents/Learn.Co_Docs/Projects/Capstone/QQuarterlyInc/sec_edgar_filings/ALGT/10-Q/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baker Hughes Co: BKR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get all 10-Q filings (ticker: BKR )\n",
    "# dl.get(\"10-Q\", \"BKR\", after_date=\"20160101\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating the path to list of 10-Qs\n",
    "BKR_Path =  \"/Users/boimoriba/Documents/Learn.Co_Docs/Projects/Capstone/QQuarterlyInc/sec_edgar_filings/BKR/10-Q/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baxter International Inc: BAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get all 10-Q filings (ticker: BAX )\n",
    "# dl.get(\"10-Q\", \"BAX\", after_date=\"20160101\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating the path to list of 10-Qs\n",
    "BAX_Path = \"/Users/boimoriba/Documents/Learn.Co_Docs/Projects/Capstone/QQuarterlyInc/sec_edgar_filings/BAX/10-Q/\"   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boeing Co: BA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get all 10-Q filings (ticker: BA )\n",
    "# dl.get(\"10-Q\", \"BA\", after_date=\"20160101\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating the path to list of 10-Qs\n",
    "BA_Path =  \"/Users/boimoriba/Documents/Learn.Co_Docs/Projects/Capstone/QQuarterlyInc/sec_edgar_filings/BA/10-Q/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Devon Energy Corp: DVN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get all 10-Q filings (ticker: DVN )\n",
    "# dl.get(\"10-Q\", \"DVN\", after_date=\"20160101\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating the path to list of 10-Qs\n",
    "DVN_Path = \"/Users/boimoriba/Documents/Learn.Co_Docs/Projects/Capstone/QQuarterlyInc/sec_edgar_filings/DVN/10-Q/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goldman Sachs Group Inc: GS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get all 10-Q filings (ticker: GS )\n",
    "# dl.get(\"10-Q\", \"GS\", after_date=\"20160101\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating the path to list of 10-Qs\n",
    "GS_Path = \"/Users/boimoriba/Documents/Learn.Co_Docs/Projects/Capstone/QQuarterlyInc/sec_edgar_filings/GS/10-Q/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Johnson & Johnson: JNJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get all 10-Q filings (ticker: JNJ )\n",
    "# dl.get(\"10-Q\", \"JNJ\", after_date=\"20160101\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating the path to list of 10-Qs\n",
    "JNJ_Path = \"/Users/boimoriba/Documents/Learn.Co_Docs/Projects/Capstone/QQuarterlyInc/sec_edgar_filings/JNJ/10-Q/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mastercard Inc: MA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get all 10-Q filings (ticker: MA )\n",
    "# dl.get(\"10-Q\", \"MA\", after_date=\"20160101\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating the path to list of 10-Qs\n",
    "MA_Path = \"/Users/boimoriba/Documents/Learn.Co_Docs/Projects/Capstone/QQuarterlyInc/sec_edgar_filings/MA/10-Q/\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Morgan Stanley: MS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get all 10-Q filings (ticker: MS )\n",
    "# dl.get(\"10-Q\", \"MS\", after_date=\"20160101\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating the path to list of 10-Qs\n",
    "MS_Path =  \"/Users/boimoriba/Documents/Learn.Co_Docs/Projects/Capstone/QQuarterlyInc/sec_edgar_filings/MS/10-Q/\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Philip Morris International Inc.: PM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get all 10-Q filings (ticker: PM )\n",
    "# dl.get(\"10-Q\", \"PM\", after_date=\"20160101\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating the path to list of 10-Qs\n",
    "PM_Path = \"/Users/boimoriba/Documents/Learn.Co_Docs/Projects/Capstone/QQuarterlyInc/sec_edgar_filings/PM/10-Q/\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prudential Financial Inc: PRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get all 10-Q filings (ticker: PRU )\n",
    "# dl.get(\"10-Q\", \"PRU\", after_date=\"20160101\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating the path to list of 10-Qs\n",
    "PRU_Path = \"/Users/boimoriba/Documents/Learn.Co_Docs/Projects/Capstone/QQuarterlyInc/sec_edgar_filings/PRU/10-Q/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raytheon Technologies Corp: RTX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get all 10-Q filings (ticker: RTX )\n",
    "# dl.get(\"10-Q\", \"RTX\", after_date=\"20160101\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating the path to list of 10-Qs\n",
    "RTX_Path = \"/Users/boimoriba/Documents/Learn.Co_Docs/Projects/Capstone/QQuarterlyInc/sec_edgar_filings/RTX/10-Q/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simon Property Group Inc: SPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get all 10-Q filings (ticker: SPG)\n",
    "# dl.get(\"10-Q\", \"SPG\", after_date=\"20160101\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating the path to list of 10-Qs\n",
    "SPG_Path =  \"/Users/boimoriba/Documents/Learn.Co_Docs/Projects/Capstone/QQuarterlyInc/sec_edgar_filings/SPG/10-Q/\"   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skywest Inc: SKYW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get all 10-Q filings (ticker: SKYW )\n",
    "# dl.get(\"10-Q\", \"SKYW\", after_date=\"20160101\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating the path to list of 10-Qs\n",
    "SKYW_Path = \"/Users/boimoriba/Documents/Learn.Co_Docs/Projects/Capstone/QQuarterlyInc/sec_edgar_filings/SKYW/10-Q/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Southern Co: SO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get all 10-Q filings (ticker: SO )\n",
    "# dl.get(\"10-Q\", \"SO\", after_date=\"20160101\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating the path to list of 10-Qs\n",
    "SO_Path = \"/Users/boimoriba/Documents/Learn.Co_Docs/Projects/Capstone/QQuarterlyInc/sec_edgar_filings/SO/10-Q/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap Objectives:\n",
    "\n",
    "- Download needed documentation from SEC using edgar **Complete**\n",
    "- Filter documentation to only contain NYSE company files  **Complete**\n",
    "- Turn docments into data frames for an easier cleaning process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating The Data Frames\n",
    "For each path to the folders holding the needed documents for sentiment analysis, below you will find them placed in a list that will then be used in a function to turn each folder of documents into a data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "doc_path_list = [MMM_Path, ABT_Path, ACN_PATH,\n",
    "                 ALGT_Path, BKR_Path, BAX_Path,\n",
    "                 BA_Path, DVN_Path, GS_Path,\n",
    "                 JNJ_Path, MA_Path, MS_Path, \n",
    "                 PM_Path, PRU_Path, RTX_Path,\n",
    "                 SPG_Path, SKYW_Path, SO_Path]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The link for the code below is located in the reference section, as well as individuals that assisted in the coding process: Lindsey & Bryan.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''The function below will take in a list of paths to folders holding 10-Q documents \n",
    "and do the following: Reading in and parsingthe document, Remove all script and style elements, \n",
    "Assigning what's left to a string, Normalizing text format, and Get rid of characters and digits \n",
    "in document. The function will then return a dataframe  of the cleaned text with its corresponding \n",
    "file name note that del gc.collect was added to clear up memory on the computer for the function \n",
    "to know what to hold on to and what to get rid of.'''\n",
    "\n",
    "def df_conversion(path_list):\n",
    "    # Initialize dictionary\n",
    "    file_name_and_text = {}\n",
    "    \n",
    "    # Extract filenames\n",
    "    for path in path_list:\n",
    "        file_names = os.listdir(path)\n",
    "    \n",
    "    # Parse text for each file\n",
    "    for file in file_names:\n",
    "        if '.txt' in file:\n",
    "            with open(path + file, \"r\", -1, encoding=\"windows-1252\", errors='ignore') as target_file:\n",
    "                text = target_file.read()\n",
    "            target_file.close()\n",
    "\n",
    "            text = get_text(text)\n",
    "            text = unicodedata.normalize(\"NFKD\", text)\n",
    "            text = clean(text,\n",
    "                         all=True,\n",
    "                         extra_spaces=True,\n",
    "                         stemming=True,\n",
    "                         stopwords=True,\n",
    "                         lowercase=True,\n",
    "                         numbers=True,\n",
    "                         punct=True,\n",
    "                         stp_lang='english')\n",
    "\n",
    "            # Store text in dictionary\n",
    "            file_name_and_text[file] = text \n",
    "            del text; gc.collect()\n",
    "    \n",
    "    # Cast as dataframe\n",
    "    file_data = (pd.DataFrame.from_dict(file_name_and_text, orient='index')\n",
    "                 .reset_index()\n",
    "                 .rename(index = str, columns = {'index': 'file_name', 0: 'text'}))\n",
    "    \n",
    "    return file_data\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_conversion(doc_path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap Objectives:\n",
    "\n",
    "- Download needed documentation from SEC using edgar **Complete**\n",
    "- Filter documentation to only contain NYSE company files  **Complete**\n",
    "- Turn docments into data frames for an easier cleaning process **Complete**\n",
    "\n",
    "# Conclusion\n",
    "Now that the df is made, the next step is to convert it to a csv file for easier access and further cleaning of the text. The last bits of cleaning and the modeling will be done in the next notebook. Be advised, if you use this function try it on one company first! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving in 'Feather' format\n",
    "# df.reset_index().to_feather('10-Qs.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources \n",
    "\n",
    "**The Idea**\n",
    "\n",
    "The Blog That Led to This Project: https://towardsdatascience.com/useful-sentiment-analysis-mining-sec-filings-part-1-358942fc98ed\n",
    "\n",
    "**Libraries**\n",
    "\n",
    "Downloading 10-Q: https://sec-edgar-downloader.readthedocs.io/en/latest/\n",
    "\n",
    "Edgar Documentation: https://pypi.org/project/edgar/\n",
    "\n",
    "OS: https://www.geeksforgeeks.org/os-module-python-examples/\n",
    "\n",
    "Inscript: https://pypi.org/project/inscriptis/\n",
    "\n",
    "Cleantext: https://pypi.org/project/cleantext/\n",
    "\n",
    "**Companies** \n",
    "\n",
    "List of SEC Registered Companies: https://www.sec.gov/Archives/edgar/cik-lookup-data.txt\n",
    "\n",
    "**Code**\n",
    "\n",
    "Function for text to df: https://stackoverflow.com/questions/33912773/python-read-txt-files-into-a-dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Resources\n",
    "\n",
    "Bryan Arnold 02172020 DS Lead Instructor: https://www.linkedin.com/in/bryan-arnold-mathematics/\n",
    "\n",
    "Lindsey Berlin 02172020 DS Coach: https://www.linkedin.com/in/lindseyberlin/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
