{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "The focus of this notebook is to continue the NLP steps with the text data that has now been turned into a feather file (file name and its corresponding text). Within this notebook you will see the making of the baseline model and model improvements.  \n",
    "\n",
    "Beginning: The beginning of the notebook shows Unsupervised Sentiment Analysis. This was not my original goal for this project. I was not sure how to go about sentiment analysis and was under the impression that I did not have a target. After speaking with the Lead Instructor and the Coach of our program, I was able to redirect my focus and discover my target. This led to a Supervised Sentiment Anlysis. \n",
    "\n",
    "If you are interested in seeing how I began the unsupervised approach, feel free to start at the beginning of the notebook. There is also a link to a blog that talks about how to use this approach. If you want to see the supervised approach scroll down to the ***New Approach*** section of the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Importing and Manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import mean\n",
    "\n",
    "#Sentiment Analysis\n",
    "from textblob import TextBlob\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "\n",
    "# Tokenizing\n",
    "from textblob.taggers import NLTKTagger\n",
    "\n",
    "# Time series handling \n",
    "import datetime\n",
    "from datetime import date\n",
    "\n",
    "# Cleaning up memory on computer after running code\n",
    "import gc; gc.enable()\n",
    "\n",
    "# Stock market Data Library\n",
    "import yfinance as yf\n",
    "\n",
    "# import string\n",
    "\n",
    "# # String handling and NLP model\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# import nltk\n",
    "# from nltk import word_tokenize\n",
    "# from nltk.tokenize import treebank\n",
    "# # nltk.download('opinion_lexicon')\n",
    "# # nltk.download('vader_lexicon')\n",
    "# # nltk.download('punkt')\n",
    "# from nltk.corpus import opinion_lexicon\n",
    "\n",
    "# from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading from 'Feather' format\n",
    "df = pd.read_feather('/Users/boimoriba/Documents/Learn.Co_Docs/Projects/Capstone/QQuarterlyInc/CSV_Files/10-Qs.feather')\n",
    "del df['index']; gc.collect()\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape # Viewing the shape of the df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "While condicting online research I came across a YouTube video that went through using the library Textblob. In the previous notbook we were able to remove punctuations, stopwords, and digets(could not parse through because of te timeframe we have. This can be done in the near future). \n",
    "\n",
    "We were also able to nomalize the text and create a dataframe from the nomalized text and its corresponding file name. Below you will see my attemped to perform a sentiment analysis on the text data in the df we currently have. The documentation for this library is located in the Resource section. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Run 1\n",
    "**Lets try using the libray on one body of text from the df. Keep in mind the df currently holds the 10-Qs of Southern Co. between 2016-2020.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Textblob obj to be used for analysis\n",
    "obj = TextBlob(df.text[10]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returning a value between 1 & -1\n",
    "# Using initiated obj to get polarity value\n",
    "sentiment = obj.sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014091192227164666\n"
     ]
    }
   ],
   "source": [
    "print(sentiment) # Printing results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turn It Into A Function\n",
    "It worked! Now lets try this for every text body in the df by writing a function!! The below cells will consist of two function; one providing the list of sentiment polarity values for each body of text in df[*text*] & another displaying if the text is negative, positive or neutral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This function will take in the df as an argument and \n",
    "iterate through the text column that is sliced to the body \n",
    "of text its self and return a list of sentiment polarity value \n",
    "for each body of text'''\n",
    "def sentiment_ana(df):\n",
    "    sentiments_list = []\n",
    "    i = [0,1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "    for text in df.text[i]:\n",
    "            obj = TextBlob(text)\n",
    "            sentiment = obj.sentiment.polarity\n",
    "            sentiments_list.append(sentiment)\n",
    "    return sentiments_list \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SO_Sentiments = sentiment_ana(df) # Calling function and assigning to variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.025743580469827186,\n",
       " -0.0033127985425172066,\n",
       " 0.03165365439445174,\n",
       " 0.02479712515096895,\n",
       " 0.019257323182357684,\n",
       " 0.018702514236993255,\n",
       " 0.014686811941619592,\n",
       " 0.030788767127009578,\n",
       " 0.024793322909917113,\n",
       " 0.047629955462548425,\n",
       " 0.014091192227164666,\n",
       " 0.024803428417207694,\n",
       " 0.01055402079920463]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SO_Sentiments # Viewing list of polarity values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qucik Observation\n",
    "Now that we have a list of floats that represent each body of text in the df (all 13 10-Qs for Southern Co), lets find the avereage the get and idea of what the over all sentiment of the documents are. You will see the overall language of the documents are positive. But we need a model to predict the next documents sentiment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02186068444436564\n",
      "The Text Is Positive\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SA_Mean = mean(SO_Sentiments)\n",
    "if SA_Mean == 0: \n",
    "    print(SA_Mean)\n",
    "    print('The text Is Neutral')\n",
    "    print('\\n') \n",
    "elif SA_Mean > 0:\n",
    "    print(SA_Mean)\n",
    "    print('The Text Is Positive')\n",
    "    print('\\n') \n",
    "else:\n",
    "    print(SA_Mean)\n",
    "    print('The Text Is Negative')\n",
    "    print('\\n') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is It Positive, Neutral or Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This function will take in the list of polarity values as an argument and \n",
    "iterate through the list, check if the value meets any of the conditions,\n",
    "and print the text that matches the values met condition.'''\n",
    "def SA(_list):\n",
    "    for sentiment in _list:\n",
    "        if sentiment == 0: \n",
    "            print(sentiment)\n",
    "            print('The text Is Neutral')\n",
    "            print('\\n') \n",
    "        elif sentiment > 0:\n",
    "            print(sentiment)\n",
    "            print('The Text Is Positive')\n",
    "            print('\\n') \n",
    "        else:\n",
    "            print(sentiment)\n",
    "            print('The Text Is Negative')\n",
    "            print('\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.025743580469827186\n",
      "The Text Is Positive\n",
      "\n",
      "\n",
      "-0.0033127985425172066\n",
      "The Text Is Negative\n",
      "\n",
      "\n",
      "0.03165365439445174\n",
      "The Text Is Positive\n",
      "\n",
      "\n",
      "0.02479712515096895\n",
      "The Text Is Positive\n",
      "\n",
      "\n",
      "0.019257323182357684\n",
      "The Text Is Positive\n",
      "\n",
      "\n",
      "0.018702514236993255\n",
      "The Text Is Positive\n",
      "\n",
      "\n",
      "0.014686811941619592\n",
      "The Text Is Positive\n",
      "\n",
      "\n",
      "0.030788767127009578\n",
      "The Text Is Positive\n",
      "\n",
      "\n",
      "0.024793322909917113\n",
      "The Text Is Positive\n",
      "\n",
      "\n",
      "0.047629955462548425\n",
      "The Text Is Positive\n",
      "\n",
      "\n",
      "0.014091192227164666\n",
      "The Text Is Positive\n",
      "\n",
      "\n",
      "0.024803428417207694\n",
      "The Text Is Positive\n",
      "\n",
      "\n",
      "0.01055402079920463\n",
      "The Text Is Positive\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Sentiment_Results = SA(SO_Sentiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Run 2\n",
    "Looking into the advance use of Textblob I was able to find code that can do the sentiment analysis of the text for me, in just a few lines of code. This code was taken from the Textblod documentation. The link to this code is provided in the Resource Section of the notebook. Lets test out this code  ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(classification='pos', p_pos=1.0, p_neg=7.994055237498093e-59)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLTK classifier trained on a movie reviews corpus.\n",
    "# Using trained NB Analyzer to do sentiment analysis on a body of text\n",
    "blob = TextBlob(df.text[0], analyzer=NaiveBayesAnalyzer())\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This function will take in the df as an argument and \n",
    "iterate through the text column that is sliced to the body \n",
    "of text its self and return a list of sentiment values \n",
    "for each body of text'''\n",
    "def sentiment_ana2(df):\n",
    "    sentiments_list = []\n",
    "    i = [0,1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "    for text in df.text[i]:\n",
    "            obj = TextBlob(text)\n",
    "            sentiments = obj.sentiment\n",
    "            sentiments_list.append(sentiments)\n",
    "    return sentiments_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentiment(polarity=0.025743580469827186, subjectivity=0.2540728170602351),\n",
       " Sentiment(polarity=-0.0033127985425172066, subjectivity=0.21546182328981334),\n",
       " Sentiment(polarity=0.03165365439445174, subjectivity=0.2412985417005685),\n",
       " Sentiment(polarity=0.02479712515096895, subjectivity=0.24103082251213098),\n",
       " Sentiment(polarity=0.019257323182357684, subjectivity=0.24951626760818546),\n",
       " Sentiment(polarity=0.018702514236993255, subjectivity=0.3198025500406785),\n",
       " Sentiment(polarity=0.014686811941619592, subjectivity=0.2394814773079978),\n",
       " Sentiment(polarity=0.030788767127009578, subjectivity=0.2808617455424036),\n",
       " Sentiment(polarity=0.024793322909917113, subjectivity=0.26371509564186707),\n",
       " Sentiment(polarity=0.047629955462548425, subjectivity=0.29089749264666365),\n",
       " Sentiment(polarity=0.014091192227164666, subjectivity=0.23202066756152523),\n",
       " Sentiment(polarity=0.024803428417207694, subjectivity=0.22793639634486648),\n",
       " Sentiment(polarity=0.01055402079920463, subjectivity=0.24379420524338227)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SA_p2 = sentiment_ana2(df)\n",
    "SA_p2\n",
    "# polarity is how positive or neg text is between -1 & 1\n",
    "# subjectivity is how opinionated the text seems to be, between -1 & 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Run 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This function uses a NLTK classifier that was trained\n",
    "on a movie reviews corpus. It will take in the df as an argument, \n",
    "go through each body of text in the text column and perform \n",
    "a sentiment analysis using trained NB Analyzer.\n",
    "It will return the analysis for each body of text in the df.'''\n",
    "\n",
    "def sentiment_ana3(df):\n",
    "    sentiments_list = []\n",
    "    i = [0,1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "    for text in df.text[i]:\n",
    "            blob = TextBlob(text, analyzer=NaiveBayesAnalyzer())\n",
    "            sentiments = blob.sentiment\n",
    "            sentiments_list.append(sentiments)\n",
    "    return sentiments_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "SA_p3 = sentiment_ana3(df) # Calling the function and assigning results to a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentiment(classification='pos', p_pos=1.0, p_neg=7.994055237498093e-59),\n",
       " Sentiment(classification='pos', p_pos=1.0, p_neg=1.9328015799642474e-54),\n",
       " Sentiment(classification='pos', p_pos=1.0, p_neg=8.681604915330248e-51),\n",
       " Sentiment(classification='pos', p_pos=1.0, p_neg=8.332839280044437e-45),\n",
       " Sentiment(classification='pos', p_pos=1.0, p_neg=7.02691649602693e-62),\n",
       " Sentiment(classification='pos', p_pos=1.0, p_neg=9.397962013413978e-46),\n",
       " Sentiment(classification='pos', p_pos=1.0, p_neg=4.991106707551972e-91),\n",
       " Sentiment(classification='pos', p_pos=1.0, p_neg=1.9355736723606737e-73),\n",
       " Sentiment(classification='pos', p_pos=1.0, p_neg=2.035307026919699e-60),\n",
       " Sentiment(classification='pos', p_pos=1.0, p_neg=2.438798193514326e-54),\n",
       " Sentiment(classification='pos', p_pos=1.0, p_neg=4.995200663023715e-50),\n",
       " Sentiment(classification='pos', p_pos=1.0, p_neg=2.68729553663566e-53),\n",
       " Sentiment(classification='pos', p_pos=1.0, p_neg=3.896515836791994e-65)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SA_p3 # Calling variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trouble\n",
    "The approach you seen above was an example of Unserpervised Sentiment Analysis, but I have a target! My focus is to see if the stock price went up or down for the company, after the 10-Q were filed. Using online resources I will create my target column, feature engineer my df and then build a classifier using Textblob. If you are interested on continuing the unsepervised sentiment analysis, there will be a link provided in the Resources Section. \n",
    "\n",
    "Also after looking at the documents one by one the obtain the filing date I discovered that one of the 10-Q documents belonged to another company, this must be removed from the df for a proper analysis of Southern Co.\n",
    "\n",
    "# Next Steps\n",
    "Drop the document that belongs to another company & then add following features: \n",
    "- Date 10-Q was filed\n",
    "- Highs, lows, closing and opening stock price for date a week before file date\n",
    "- Highs, lows, closing and opening stock price for file date\n",
    "- Calculate the sentiment polarity and subjective value\n",
    "\n",
    "**Target: Yes Or No Stock Price Increased**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "The data frame doesn't have much info needed for a proper analysis. I am aimming to have a great performing model, to have that I need more information for my model to learn from. In this section you will see feature engineering of the data I have as well as added data I didn't have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the document that belongs to another company\n",
    "df2 = df.drop(index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0000092122-18-000050.txt</td>\n",
       "      <td>txt hdrsgml access number conform submiss type...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0000092122-19-000016.txt</td>\n",
       "      <td>txt hdrsgml access number conform submiss type...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0000092122-18-000027.txt</td>\n",
       "      <td>txt hdrsgml access number conform submiss type...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0000092122-16-000213.txt</td>\n",
       "      <td>txt hdrsgml access number conform submiss type...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0000092122-20-000042.txt</td>\n",
       "      <td>txt hdrsgml access number conform submiss type...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  file_name                                               text\n",
       "1  0000092122-18-000050.txt  txt hdrsgml access number conform submiss type...\n",
       "2  0000092122-19-000016.txt  txt hdrsgml access number conform submiss type...\n",
       "3  0000092122-18-000027.txt  txt hdrsgml access number conform submiss type...\n",
       "4  0000092122-16-000213.txt  txt hdrsgml access number conform submiss type...\n",
       "5  0000092122-20-000042.txt  txt hdrsgml access number conform submiss type..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head() # Checking work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date 10-Q Was Filed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating date filed column\n",
    "df2['Date_Filed']= [20180808,\n",
    " 20190501,\n",
    " 20180502,\n",
    " 20161104,\n",
    " 20200430,\n",
    " 20170802,\n",
    " 20160505,\n",
    " 20160808,\n",
    " 20191030,\n",
    " 20171101,\n",
    " 20190731,\n",
    " 20181107]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>text</th>\n",
       "      <th>Date_Filed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0000092122-16-000144.txt</td>\n",
       "      <td>txt hdrsgml access number conform submiss type...</td>\n",
       "      <td>20160505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0000092122-16-000179.txt</td>\n",
       "      <td>txt hdrsgml access number conform submiss type...</td>\n",
       "      <td>20160808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0000092122-16-000213.txt</td>\n",
       "      <td>txt hdrsgml access number conform submiss type...</td>\n",
       "      <td>20161104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0000092122-17-000065.txt</td>\n",
       "      <td>txt hdrsgml access number conform submiss type...</td>\n",
       "      <td>20170802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0000092122-17-000076.txt</td>\n",
       "      <td>txt hdrsgml access number conform submiss type...</td>\n",
       "      <td>20171101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0000092122-18-000027.txt</td>\n",
       "      <td>txt hdrsgml access number conform submiss type...</td>\n",
       "      <td>20180502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0000092122-18-000050.txt</td>\n",
       "      <td>txt hdrsgml access number conform submiss type...</td>\n",
       "      <td>20180808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0000092122-18-000062.txt</td>\n",
       "      <td>txt hdrsgml access number conform submiss type...</td>\n",
       "      <td>20181107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0000092122-19-000016.txt</td>\n",
       "      <td>txt hdrsgml access number conform submiss type...</td>\n",
       "      <td>20190501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0000092122-19-000037.txt</td>\n",
       "      <td>txt hdrsgml access number conform submiss type...</td>\n",
       "      <td>20190731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0000092122-19-000053.txt</td>\n",
       "      <td>txt hdrsgml access number conform submiss type...</td>\n",
       "      <td>20191030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0000092122-20-000042.txt</td>\n",
       "      <td>txt hdrsgml access number conform submiss type...</td>\n",
       "      <td>20200430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   file_name  \\\n",
       "7   0000092122-16-000144.txt   \n",
       "8   0000092122-16-000179.txt   \n",
       "4   0000092122-16-000213.txt   \n",
       "6   0000092122-17-000065.txt   \n",
       "10  0000092122-17-000076.txt   \n",
       "3   0000092122-18-000027.txt   \n",
       "1   0000092122-18-000050.txt   \n",
       "12  0000092122-18-000062.txt   \n",
       "2   0000092122-19-000016.txt   \n",
       "11  0000092122-19-000037.txt   \n",
       "9   0000092122-19-000053.txt   \n",
       "5   0000092122-20-000042.txt   \n",
       "\n",
       "                                                 text  Date_Filed  \n",
       "7   txt hdrsgml access number conform submiss type...    20160505  \n",
       "8   txt hdrsgml access number conform submiss type...    20160808  \n",
       "4   txt hdrsgml access number conform submiss type...    20161104  \n",
       "6   txt hdrsgml access number conform submiss type...    20170802  \n",
       "10  txt hdrsgml access number conform submiss type...    20171101  \n",
       "3   txt hdrsgml access number conform submiss type...    20180502  \n",
       "1   txt hdrsgml access number conform submiss type...    20180808  \n",
       "12  txt hdrsgml access number conform submiss type...    20181107  \n",
       "2   txt hdrsgml access number conform submiss type...    20190501  \n",
       "11  txt hdrsgml access number conform submiss type...    20190731  \n",
       "9   txt hdrsgml access number conform submiss type...    20191030  \n",
       "5   txt hdrsgml access number conform submiss type...    20200430  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making sure the dates or in ascending order & viewing work\n",
    "df2 = df2.sort_values(by=['Date_Filed'], ascending = True)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap \n",
    "Drop the document that belongs to another company (**Complete**) & then add following features:\n",
    "\n",
    "- Date 10-Q was filed **Complete**\n",
    "\n",
    "- Highs, lows, closing and opening stock price for date a week before file date\n",
    "\n",
    "- Highs, lows, closing and opening stock price for file date\n",
    "\n",
    "- Calculate the sentiment polarity and subjective value\n",
    "\n",
    "**Target: Yes Or No Stock Price Increased**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Highs, Lows, Closing, & Opening Stock Price A Week Before File Date\n",
    "In this section I am assigning the  list of high, low, open, close, and adj close prices to a variable I can call later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Opening_bfd'] = [49.28,\n",
    "                  53.44,\n",
    "                  53.44,\n",
    "                  46.78,\n",
    "                  52.18,\n",
    "                  45.59,\n",
    "                  48.42,\n",
    "                  45.50,\n",
    "                  51.88,\n",
    "                  55.46,\n",
    "                  61.43,\n",
    "                  57.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Highs_bfd'] = [49.96,\n",
    "                   53.80,\n",
    "                   53.80,\n",
    "                   47.40,\n",
    "                   52.33,\n",
    "                   46.32,\n",
    "                   48.47,\n",
    "                   45.50,\n",
    "                   52.37,\n",
    "                   55.67,\n",
    "                   61.95,\n",
    "                   57.50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Lows_bfd'] = [49.13,\n",
    "                  53.37,\n",
    "                  53.37,\n",
    "                  46.71,\n",
    "                  51.69,\n",
    "                  45.57,\n",
    "                  47.66,\n",
    "                  44.62,\n",
    "                  51.84,\n",
    "                  55.10,\n",
    "                  61.43,\n",
    "                  56.10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Closing_bfd'] = [49.95,\n",
    "                     53.65,\n",
    "                     53.65,\n",
    "                     47.40,\n",
    "                     52.21,\n",
    "                     46.03,\n",
    "                     48.08,\n",
    "                     45.03,\n",
    "                     52.23,\n",
    "                     55.64,\n",
    "                     61.95,\n",
    "                     56.80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['AdjClosing_bfd'] = [40.99,\n",
    "                        44.52,\n",
    "                        44.52,\n",
    "                        41.17,\n",
    "                        45.89,\n",
    "                        41.46,\n",
    "                        43.91,\n",
    "                        41.65,\n",
    "                        49.53,\n",
    "                        53.38,\n",
    "                        60.08,\n",
    "                        56.14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Highs, Lows, Closing, & Opening Stock Price For File Date\n",
    "In this section I am assigning the  list of high, low, open, close, and adj close prices to a variable I can call later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Opening_ofd'] = [51.15,\n",
    "                52.71,\n",
    "                50.66,\n",
    "                48.51,\n",
    "                49.17,\n",
    "                45.81,\n",
    "                47.45,\n",
    "                43.81,\n",
    "                52.23,\n",
    "                55.75,\n",
    "                61.01,\n",
    "                59.22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Highs_ofd'] = [51.56,\n",
    "                53.04,\n",
    "                50.66,\n",
    "                50.08,\n",
    "                49.44,\n",
    "                46.43,\n",
    "                47.50,\n",
    "                44.34,\n",
    "                53.21,\n",
    "                56.64,\n",
    "                62.88,\n",
    "                59.30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Lows_ofd'] = [50.34,\n",
    "               52.44,\n",
    "               49.54,\n",
    "               47.91,\n",
    "               48.95,\n",
    "               45.62,\n",
    "               46.70,\n",
    "               43.67,\n",
    "               52.16,\n",
    "               55.15,\n",
    "               61.00,\n",
    "                57.27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Closing_ofd'] = [50.62,\n",
    "                  52.69,\n",
    "                  49.84,\n",
    "                  49.78,\n",
    "                  49.14,\n",
    "                  46.25,\n",
    "                  46.88,\n",
    "                  43.92,\n",
    "                  52.52,\n",
    "                  56.20,\n",
    "                  62.63,\n",
    "                  57.37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['AdjClosing_ofd'] = [41.54,\n",
    "                     43.72,\n",
    "                     41.80,\n",
    "                     43.24,\n",
    "                     43.19,\n",
    "                     41.65,\n",
    "                     42.81,\n",
    "                     40.62,\n",
    "                     49.81,\n",
    "                     53.91,\n",
    "                     60.74,\n",
    "                     56.70]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate The Sentiment Polarity & Subjective Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Code used below cam from Alice Zhao Link to github will be in Resource Section\n",
    "# Code used to calculate the sentiment polar and subjective value\n",
    "pol = lambda x: TextBlob(x).sentiment.polarity\n",
    "sub = lambda x: TextBlob(x).sentiment.subjectivity\n",
    "\n",
    "df2['polarity'] = df['text'].apply(pol)\n",
    "df2['subjectivity'] = df['text'].apply(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>text</th>\n",
       "      <th>Date_Filed</th>\n",
       "      <th>Opening_bfd</th>\n",
       "      <th>Highs_bfd</th>\n",
       "      <th>Lows_bfd</th>\n",
       "      <th>Closing_bfd</th>\n",
       "      <th>AdjClosing_bfd</th>\n",
       "      <th>Opening_ofd</th>\n",
       "      <th>Highs_ofd</th>\n",
       "      <th>Lows_ofd</th>\n",
       "      <th>Closing_ofd</th>\n",
       "      <th>AdjClosing_ofd</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0000092122-16-000144.txt</td>\n",
       "      <td>txt hdrsgml access number conform submiss type...</td>\n",
       "      <td>20160505</td>\n",
       "      <td>49.28</td>\n",
       "      <td>49.96</td>\n",
       "      <td>49.13</td>\n",
       "      <td>49.95</td>\n",
       "      <td>40.99</td>\n",
       "      <td>51.15</td>\n",
       "      <td>51.56</td>\n",
       "      <td>50.34</td>\n",
       "      <td>50.62</td>\n",
       "      <td>41.54</td>\n",
       "      <td>0.030789</td>\n",
       "      <td>0.280862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0000092122-16-000179.txt</td>\n",
       "      <td>txt hdrsgml access number conform submiss type...</td>\n",
       "      <td>20160808</td>\n",
       "      <td>53.44</td>\n",
       "      <td>53.80</td>\n",
       "      <td>53.37</td>\n",
       "      <td>53.65</td>\n",
       "      <td>44.52</td>\n",
       "      <td>52.71</td>\n",
       "      <td>53.04</td>\n",
       "      <td>52.44</td>\n",
       "      <td>52.69</td>\n",
       "      <td>43.72</td>\n",
       "      <td>0.024793</td>\n",
       "      <td>0.263715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0000092122-16-000213.txt</td>\n",
       "      <td>txt hdrsgml access number conform submiss type...</td>\n",
       "      <td>20161104</td>\n",
       "      <td>53.44</td>\n",
       "      <td>53.80</td>\n",
       "      <td>53.37</td>\n",
       "      <td>53.65</td>\n",
       "      <td>44.52</td>\n",
       "      <td>50.66</td>\n",
       "      <td>50.66</td>\n",
       "      <td>49.54</td>\n",
       "      <td>49.84</td>\n",
       "      <td>41.80</td>\n",
       "      <td>0.019257</td>\n",
       "      <td>0.249516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  file_name  \\\n",
       "7  0000092122-16-000144.txt   \n",
       "8  0000092122-16-000179.txt   \n",
       "4  0000092122-16-000213.txt   \n",
       "\n",
       "                                                text  Date_Filed  Opening_bfd  \\\n",
       "7  txt hdrsgml access number conform submiss type...    20160505        49.28   \n",
       "8  txt hdrsgml access number conform submiss type...    20160808        53.44   \n",
       "4  txt hdrsgml access number conform submiss type...    20161104        53.44   \n",
       "\n",
       "   Highs_bfd  Lows_bfd  Closing_bfd  AdjClosing_bfd  Opening_ofd  Highs_ofd  \\\n",
       "7      49.96     49.13        49.95           40.99        51.15      51.56   \n",
       "8      53.80     53.37        53.65           44.52        52.71      53.04   \n",
       "4      53.80     53.37        53.65           44.52        50.66      50.66   \n",
       "\n",
       "   Lows_ofd  Closing_ofd  AdjClosing_ofd  polarity  subjectivity  \n",
       "7     50.34        50.62           41.54  0.030789      0.280862  \n",
       "8     52.44        52.69           43.72  0.024793      0.263715  \n",
       "4     49.54        49.84           41.80  0.019257      0.249516  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2.Date_Filed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap \n",
    "Drop the document that belongs to another company (**Complete**) & then add following features:\n",
    "\n",
    "- Date 10-Q was filed **Complete**\n",
    "\n",
    "- Highs, lows, closing and opening stock price for date a week before file date **Complete**\n",
    "\n",
    "- Highs, lows, closing and opening stock price for file date **Complete**\n",
    "\n",
    "- Calculate the sentiment polarity and subjective value **Complete**\n",
    "\n",
    "**Target: Yes Or No Stock Price Increased**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['file_name', 'text', 'Date_Filed', 'Opening_bfd', 'Highs_bfd',\n",
       "       'Lows_bfd', 'Closing_bfd', 'AdjClosing_bfd', 'Opening_ofd', 'Highs_ofd',\n",
       "       'Lows_ofd', 'Closing_ofd', 'AdjClosing_ofd', 'polarity',\n",
       "       'subjectivity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns # What columns are we working with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Opening_ofd       51.456667\n",
       "Highs_ofd         52.090000\n",
       "Lows_ofd          50.895833\n",
       "Closing_ofd       51.486667\n",
       "AdjClosing_ofd    46.644167\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the average of the stock prices and assigning them to a variable\n",
    "ofd_Average = df2[['Opening_ofd', 'Highs_ofd',\n",
    "       'Lows_ofd', 'Closing_ofd', 'AdjClosing_ofd']].mean(axis=0)\n",
    "ofd_Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Opening_bfd       51.700833\n",
       "Highs_bfd         52.089167\n",
       "Lows_bfd          51.382500\n",
       "Closing_bfd       51.885000\n",
       "AdjClosing_bfd    46.936667\n",
       "dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the average of the stock prices and assigning them to a variable\n",
    "bfd_Average = df2[['Opening_bfd', 'Highs_bfd',\n",
    "       'Lows_bfd', 'Closing_bfd', 'AdjClosing_bfd']].mean(axis=0)\n",
    "bfd_Average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This was an attempt to create a target column, at this point I checked in with the instructor and coach. I was was able to get the guidence need to reapproach the analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def target_list(average_list):\n",
    "#     target = []\n",
    "#     value = 0\n",
    "#     for ofd in ofd_Average:\n",
    "#         for bfd in bfd_Average:\n",
    "#             if ofd > bfd:\n",
    "#                 target.append(value)\n",
    "#                 value += 1 \n",
    "#             else: \n",
    "#                 return target   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Approach\n",
    "In this section you will see the process of supervised sentiment analysis. The code for using the yahoo finance library was provided by Bryan Arnold, his info will be linked in the Reasource section below.\n",
    "\n",
    "**Focus:** I want to look at the relationship between the sentiment analysis of a 10-Q and the stock price. Percent change will be my target. \n",
    "\n",
    "Objectives:\n",
    "- Clean up & feature engineer original df \n",
    "- Locate the dates in hist df that match up with the dates in the SO df \n",
    "- Merge the two after dates are located in hist\n",
    "- Grabbing historical price data for S&P 500\n",
    "- Merging the historical price data for to the new df \n",
    "- Calculate the % change for SO & S&P 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# Downloading historical price data for Southern Co\n",
    "# ticker = 'SO'\n",
    "hist = yf.download('SO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ticker = '^GSPC' # Doing the same for S&P500 Index\n",
    "# hist = yf.download(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1981-12-31</td>\n",
       "      <td>3.703581</td>\n",
       "      <td>3.741762</td>\n",
       "      <td>3.6654</td>\n",
       "      <td>3.665400</td>\n",
       "      <td>0.048629</td>\n",
       "      <td>220900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1982-01-04</td>\n",
       "      <td>3.703581</td>\n",
       "      <td>3.741762</td>\n",
       "      <td>3.6654</td>\n",
       "      <td>3.741762</td>\n",
       "      <td>0.049642</td>\n",
       "      <td>365000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1982-01-05</td>\n",
       "      <td>3.818125</td>\n",
       "      <td>3.932669</td>\n",
       "      <td>3.6654</td>\n",
       "      <td>3.703581</td>\n",
       "      <td>0.049136</td>\n",
       "      <td>666500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1982-01-06</td>\n",
       "      <td>3.703581</td>\n",
       "      <td>3.741762</td>\n",
       "      <td>3.6654</td>\n",
       "      <td>3.703581</td>\n",
       "      <td>0.049136</td>\n",
       "      <td>500900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1982-01-07</td>\n",
       "      <td>3.703581</td>\n",
       "      <td>3.703581</td>\n",
       "      <td>3.6654</td>\n",
       "      <td>3.665400</td>\n",
       "      <td>0.048629</td>\n",
       "      <td>171500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Open      High     Low     Close  Adj Close  Volume\n",
       "Date                                                               \n",
       "1981-12-31  3.703581  3.741762  3.6654  3.665400   0.048629  220900\n",
       "1982-01-04  3.703581  3.741762  3.6654  3.741762   0.049642  365000\n",
       "1982-01-05  3.818125  3.932669  3.6654  3.703581   0.049136  666500\n",
       "1982-01-06  3.703581  3.741762  3.6654  3.703581   0.049136  500900\n",
       "1982-01-07  3.703581  3.703581  3.6654  3.665400   0.048629  171500"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.head() # Viewing the price data that was collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9681, 6)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 9681 entries, 1981-12-31 to 2020-05-22\n",
      "Data columns (total 6 columns):\n",
      "Open         9681 non-null float64\n",
      "High         9681 non-null float64\n",
      "Low          9681 non-null float64\n",
      "Close        9681 non-null float64\n",
      "Adj Close    9681 non-null float64\n",
      "Volume       9681 non-null int64\n",
      "dtypes: float64(5), int64(1)\n",
      "memory usage: 529.4 KB\n"
     ]
    }
   ],
   "source": [
    "hist.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulling the year and month from the price data\n",
    "hist['year'] = hist.index.year\n",
    "hist['month'] = hist.index.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulling the quarter the stock price was in \n",
    "hist['qrtr'] = hist.month // 4 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>qrtr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1981-12-31</td>\n",
       "      <td>3.703581</td>\n",
       "      <td>3.741762</td>\n",
       "      <td>3.6654</td>\n",
       "      <td>3.665400</td>\n",
       "      <td>0.048629</td>\n",
       "      <td>220900</td>\n",
       "      <td>1981</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1982-01-04</td>\n",
       "      <td>3.703581</td>\n",
       "      <td>3.741762</td>\n",
       "      <td>3.6654</td>\n",
       "      <td>3.741762</td>\n",
       "      <td>0.049642</td>\n",
       "      <td>365000</td>\n",
       "      <td>1982</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1982-01-05</td>\n",
       "      <td>3.818125</td>\n",
       "      <td>3.932669</td>\n",
       "      <td>3.6654</td>\n",
       "      <td>3.703581</td>\n",
       "      <td>0.049136</td>\n",
       "      <td>666500</td>\n",
       "      <td>1982</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1982-01-06</td>\n",
       "      <td>3.703581</td>\n",
       "      <td>3.741762</td>\n",
       "      <td>3.6654</td>\n",
       "      <td>3.703581</td>\n",
       "      <td>0.049136</td>\n",
       "      <td>500900</td>\n",
       "      <td>1982</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1982-01-07</td>\n",
       "      <td>3.703581</td>\n",
       "      <td>3.703581</td>\n",
       "      <td>3.6654</td>\n",
       "      <td>3.665400</td>\n",
       "      <td>0.048629</td>\n",
       "      <td>171500</td>\n",
       "      <td>1982</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Open      High     Low     Close  Adj Close  Volume  year  \\\n",
       "Date                                                                        \n",
       "1981-12-31  3.703581  3.741762  3.6654  3.665400   0.048629  220900  1981   \n",
       "1982-01-04  3.703581  3.741762  3.6654  3.741762   0.049642  365000  1982   \n",
       "1982-01-05  3.818125  3.932669  3.6654  3.703581   0.049136  666500  1982   \n",
       "1982-01-06  3.703581  3.741762  3.6654  3.703581   0.049136  500900  1982   \n",
       "1982-01-07  3.703581  3.703581  3.6654  3.665400   0.048629  171500  1982   \n",
       "\n",
       "            month  qrtr  \n",
       "Date                     \n",
       "1981-12-31     12     4  \n",
       "1982-01-04      1     1  \n",
       "1982-01-05      1     1  \n",
       "1982-01-06      1     1  \n",
       "1982-01-07      1     1  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.head() # Viewing the new added features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Finding the average of the adj closing price for 2009 in quater 2\n",
    "key = ((hist.qrtr == 2) & (hist.year == 2009))\n",
    "before = hist.loc[key, 'Adj Close'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the average of the adj closing price for 2009 in quater 3\n",
    "key = ((hist.qrtr == 3) & (hist.year == 2009))\n",
    "after = hist.loc[key, 'Adj Close'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07517774524384291"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating the percent change for those averages \n",
    "(after-before)/before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply It To The Dataframe\n",
    "In this section I will locate the dates from the hist dataframe that match up with the filing dates in the SO text dataframe. From there I will merge the two dataframes making it easier to work with. I will be doing more feature engineering using the code in the cells above. \n",
    "\n",
    "This will give me the needed prices, quarter of price, year and month of price. With this the percentage change can be calculated. From there I will check for correlations between the % change in price for Southern co & the sentiment values. If there is a high correlation this proves that the quarterly reports have an impact on the stock price. I will do working with first dataframe for the beginning of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0000092122-17-000024.txt</td>\n",
       "      <td>txt hdrsgml access number conform submiss type...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0000092122-18-000050.txt</td>\n",
       "      <td>txt hdrsgml access number conform submiss type...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0000092122-19-000016.txt</td>\n",
       "      <td>txt hdrsgml access number conform submiss type...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0000092122-18-000027.txt</td>\n",
       "      <td>txt hdrsgml access number conform submiss type...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0000092122-16-000213.txt</td>\n",
       "      <td>txt hdrsgml access number conform submiss type...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  file_name                                               text\n",
       "0  0000092122-17-000024.txt  txt hdrsgml access number conform submiss type...\n",
       "1  0000092122-18-000050.txt  txt hdrsgml access number conform submiss type...\n",
       "2  0000092122-19-000016.txt  txt hdrsgml access number conform submiss type...\n",
       "3  0000092122-18-000027.txt  txt hdrsgml access number conform submiss type...\n",
       "4  0000092122-16-000213.txt  txt hdrsgml access number conform submiss type..."
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() # Viewing the df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Making sure the dates or in ascending order & viewing work\n",
    "# df = df.sort_values(by=['file_name'], ascending = True)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(index=0) # Dropping unwanted file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating date filed column\n",
    "df['Dates_Filed']= ['2016-5-5',\n",
    "                  ' 2016-8-8',\n",
    "                   '2016-11-4',\n",
    "                   '2017-8-2',\n",
    "                   '2017-11-1',\n",
    "                  ' 2018-5-2',\n",
    "                   '2018-8-8',\n",
    "                   '2018-11-7',\n",
    "                   '2019-5-1',\n",
    "                   '2019-7-31',\n",
    "                   '2019-10-30',\n",
    "                   '2020-4-30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = 'file_name', inplace = True) # dropping unwanted column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('Dates_Filed', inplace = True) # Setting date to index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis On DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code used below cam from Alice Zhao Link to github will be in Resource Section\n",
    "# Code used to calculate the sentiment polar and subjective value\n",
    "pol = lambda x: TextBlob(x).sentiment.polarity\n",
    "sub = lambda x: TextBlob(x).sentiment.subjectivity\n",
    "\n",
    "df['polarity'] = df['text'].apply(pol)\n",
    "df['subjectivity'] = df['text'].apply(sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# String To Datatime Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date_of_Filing'] = pd.to_datetime(df['Dates_Filed']) # Creating column with datetime objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 12 entries, 2016-5-5 to 2020-4-30\n",
      "Data columns (total 3 columns):\n",
      "text            12 non-null object\n",
      "polarity        12 non-null float64\n",
      "subjectivity    12 non-null float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 384.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df.info() # Checking work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Index Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('Date_of_Filing', inplace = True) # setting date time object to index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = 'Dates_Filed', inplace = True) # dropping unwanted columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date_of_Filing</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2016-05-05</td>\n",
       "      <td>txt hdrsgml access number conform submiss type...</td>\n",
       "      <td>-0.003313</td>\n",
       "      <td>0.215462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2016-08-08</td>\n",
       "      <td>txt hdrsgml access number conform submiss type...</td>\n",
       "      <td>0.031654</td>\n",
       "      <td>0.241299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2016-11-04</td>\n",
       "      <td>txt hdrsgml access number conform submiss type...</td>\n",
       "      <td>0.024797</td>\n",
       "      <td>0.241031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2017-08-02</td>\n",
       "      <td>txt hdrsgml access number conform submiss type...</td>\n",
       "      <td>0.019257</td>\n",
       "      <td>0.249516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>txt hdrsgml access number conform submiss type...</td>\n",
       "      <td>0.018703</td>\n",
       "      <td>0.319803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             text  polarity  \\\n",
       "Date_of_Filing                                                                \n",
       "2016-05-05      txt hdrsgml access number conform submiss type... -0.003313   \n",
       "2016-08-08      txt hdrsgml access number conform submiss type...  0.031654   \n",
       "2016-11-04      txt hdrsgml access number conform submiss type...  0.024797   \n",
       "2017-08-02      txt hdrsgml access number conform submiss type...  0.019257   \n",
       "2017-11-01      txt hdrsgml access number conform submiss type...  0.018703   \n",
       "\n",
       "                subjectivity  \n",
       "Date_of_Filing                \n",
       "2016-05-05          0.215462  \n",
       "2016-08-08          0.241299  \n",
       "2016-11-04          0.241031  \n",
       "2017-08-02          0.249516  \n",
       "2017-11-01          0.319803  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() # Checking work "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap\n",
    "- Clean up & feature engineer original df **Complete**\n",
    "- Locate the dates in hist df that match up with the dates in the SO df\n",
    "- Merge the two after dates are located in hist\n",
    "- Grabbing historical price data for S&P 500\n",
    "- Merging the historical price data for to the new df \n",
    "- Calculate the % change for SO & S&P 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename_axis(index={'Date_of_Filing': 'Date'}, inplace=True) \n",
    "# Renaming the index in df so merge can happen smoothly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_df = hist.loc[df.index] # Locating rows in hist df that match with the rows in the SO df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mer = pd.merge(df, hist_df, left_index=True, right_index=True) # Merging the two df together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_mer # Checking the merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_mer.info() # Checking the details of new df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap\n",
    "- Clean up & feature engineer original df **Complete**\n",
    "- Locate the dates in hist df that match up with the dates in the SO df **Complete**\n",
    "- Merge the two after dates are located in hist **Complete**\n",
    "- Grabbing historical price data for S&P 500\n",
    "- Merging the historical price data for to the new df \n",
    "- Calculate the % change for SO & S&P 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''The function below will take in a quarter and a year \n",
    "and calulate the average of thier adjusted closing price for \n",
    "Southern Co.'''\n",
    "\n",
    "def SO_adj_avg(d, yr):\n",
    "    key = ((hist.qrtr == d) & (hist.year == yr))\n",
    "    avg= hist.loc[key, 'Adj Close'].mean()\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46.20323612650887"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SO_adj_avg(1, 2019) # Calling function for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''Creating a function that will print all the averages with there corresponding quater and year'''\n",
    "def SO_avg_list():\n",
    "    for d in range(1, 4):\n",
    "        for yr in range(2016, 2020):\n",
    "            print(f'Quarter:', d)\n",
    "            print(f'Year:', yr)\n",
    "            print(SO_adj_avg(d, yr), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S&P 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# Downloading historical price data for S&P 500\n",
    "hist_sp500 = yf.download('^GSPC')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''The function below will take in a quarter and a year \n",
    "and calulate the average of thier adjusted closing price for \n",
    "SP 500.'''\n",
    "def SP500_adj_avg(d, yr):\n",
    "    key = ((hist_sp500.qrtr == d) & (hist_sp500.year == yr))\n",
    "    avg= hist_sp500.loc[key, 'Adj Close'].mean()\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulling the year, month, and quarter from the price data of SP 500\n",
    "hist_sp500['qrtr'] = hist_sp500.index.month // 4 + 1\n",
    "hist_sp500['year'] = hist_sp500.index.year\n",
    "hist_sp500['month'] = hist_sp500.index.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Creating a function that will print all the averages with there corresponding quater and year'''\n",
    "def SP500_avg_list ():\n",
    "    for d in range(1, 4):\n",
    "        for yr in range(2016, 2020):\n",
    "            print(f'Quarter:', d)\n",
    "            print(f'Year:', yr)\n",
    "            print(SP500_adj_avg(d, yr), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating % Change SO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SO_avg_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating % Change S&P 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SP500_avg_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap\n",
    "- Clean up & feature engineer original df **Complete**\n",
    "- Locate the dates in hist df that match up with the dates in the SO df **Complete**\n",
    "- Merge the two after dates are located in hist **Complete**\n",
    "- Grabbing historical price data for S&P 500 **Complete**\n",
    "- Merging the historical price data for to the new df **Complete**\n",
    "- Calculate the % change for SO & S&P 500 **Complete**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling \n",
    "Now that the feature engineering of the data is complete, and our target is esstablished we can now beging the modeling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from textblob.classifiers import NaiveBayesClassifier\n",
    "# cl = NaiveBayesClassifier(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from textblob import TextBlob\n",
    "# blob = TextBlob(\"\", classifier=cl)\n",
    "# blob.classify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cl.accuracy(test data goes here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Food For Thought\n",
    "*\"Quarterly earnings reports are important financial updates that provide a market glimpse on how stocks will likely be valued in the future. Stock prices tend to rise when earnings results exceed market expectations while disappointing earnings results tend to lower share prices. May 17, 2017\"*\n",
    "\n",
    "https://business.inquirer.net/229677/quarterly-earnings-reports-affect-stock-prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources\n",
    "\n",
    "**Everything Textblob**\n",
    "\n",
    "Install: https://textblob.readthedocs.io/en/dev/install.html\n",
    "\n",
    "Tutorial: https://textblob.readthedocs.io/en/dev/classifiers.html#classifiers\n",
    "\n",
    "Advance: https://textblob.readthedocs.io/en/dev/advanced_usage.html\n",
    "\n",
    "**Everything YouTube**\n",
    "\n",
    "Sentiment Analysis w/ Textblob: https://www.youtube.com/watch?v=N9CT6Ggh0oE\n",
    "\n",
    "Sentiment Analysis w/ Textblob: https://www.youtube.com/watch?v=bUgKhp8YwO0\n",
    "\n",
    "**Github**\n",
    "Alice Zhao Github Notebook: https://github.com/adashofdata/nlp-in-python-tutorial/blob/master/3-Sentiment-Analysis.ipynb\n",
    "\n",
    "**Quaterly Reports Info**\n",
    "\n",
    "Fiscal Quarter (Q1, Q2, Q3, Q4): https://investinganswers.com/dictionary/q/quarter-q1-q2-q3-q4\n",
    "\n",
    "**Historical Data**\n",
    "\n",
    "Historical Prices: https://finance.yahoo.com/quote/SO/history?p=SO\n",
    "\n",
    "# Human Resources \n",
    "\n",
    "**Lead Instructor For Flatiron 02172020 DS Bootcamp**\n",
    "\n",
    "Bryan Anorld: https://www.linkedin.com/in/bryan-arnold-mathematics/\n",
    "\n",
    "**Coach For Flatiron 02172020 DS Bootcamp**\n",
    "\n",
    "Lindsey Berlin:  https://www.linkedin.com/in/lindseyberlin/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
